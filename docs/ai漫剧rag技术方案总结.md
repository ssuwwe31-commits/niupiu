# AI漫剧剧本生成：RAG落地与技术栈总结

## 🎯 项目目标

将小说内容从“原始文本参考”升级为：

👉 结构化剧情知识库 + RAG生成系统

用于：
- 学习优秀剧情规律
- 稳定生成高质量原创剧本
- 支撑AI漫剧/短剧创作

---

## 🧱 总体架构

```text
小说原文
   ↓
文本清洗
   ↓
剧情结构化拆解（LLM）
   ↓
结构化数据存储
   ↓
向量化
   ↓
RAG检索
   ↓
约束生成剧本
```

核心思想：

❌ 不只是存原文

✅ 存剧情单元（冲突、人物、情绪、作用）

---

## 📚 剧情结构化示例

原始剧情：
> 主角发现兄弟背叛，被设计入狱。

结构化后：

```json
{
  "scene": "监控室",
  "characters": ["主角", "兄弟"],
  "core_conflict": "背叛揭露",
  "emotion_curve": ["震惊", "愤怒", "绝望"],
  "plot_function": "主角跌入低谷",
  "result": "入狱"
}
```

---

## 🗃️ 推荐RAG设计（多索引）

### 1️⃣ 冲突类型索引
- 背叛
- 复仇
- 权力斗争
- 误会

### 2️⃣ 情绪索引
- 高燃
- 爽点
- 虐点
- 反转

### 3️⃣ 人物关系索引
- 情侣
- 仇敌
- 师徒

### 4️⃣ 剧情功能索引
- 开局钩子
- 高潮
- 低谷
- 转折

👉 支持精准检索剧情结构，而不是随机文本

---

## ⚙️ 推荐开源技术栈（黄金组合）

### 前端
- Vue 3
- Element Plus / Ant Design Vue
- Pinia（状态管理）

### 后端
- FastAPI
- SQLAlchemy / asyncpg（数据库ORM）
- Pydantic（数据验证）

### LLM（拆解 + 生成）
- Qwen2.5 系列（Ollama/vLLM）
- DeepSeek（备选）

### 数据库
- PostgreSQL + JSONB
- pgvector（向量检索扩展）

### Embedding模型
- bge-m3 / bge-large-zh

### RAG框架
- LlamaIndex

**选择理由**：
- 专为RAG优化，核心专注于数据索引和检索
- 对pgvector的原生支持完善，支持元数据过滤和混合检索
- 支持多阶段检索和重排序，适合多维度索引场景
- API设计直观，学习曲线平缓，社区有大量RAG最佳实践

---

## 🚀 推荐MVP路线

### 阶段1
- 小说清洗
- LLM自动拆剧情单元
- JSON + 向量存储

### 阶段2
- 冲突/情绪混合检索
- 生成单场戏

### 阶段3
- 人物一致性约束
- 长线剧情规划

---

## 👤 人物一致性设计（关键）

建议维护人物状态模型：

```json
{
  "name": "主角",
  "core_personality": "冷静、自私",
  "bottom_line": "家人不可伤害",
  "current_emotion": "愤怒80%",
  "goal": "复仇"
}
```

每场戏生成必须符合人物约束。

---

## 📈 关于OPIK（Prompt工程系统）

### ✅ 适合后期引入

用于：
- Prompt版本管理
- 多生成策略对比
- A/B测试

### ❌ MVP阶段不刚需

现阶段优先级：

1. 剧情结构化质量
2. RAG检索策略
3. 人物系统
4. 长线剧情规划
5. Prompt工程化（OPIK）

👉 OPIK是加速器，不是核心底座

---

## ⚠️ 常见误区

❌ 整章小说直接向量化
❌ 只靠Prompt碰运气写剧情
❌ 过早堆复杂系统（OPKI/复杂Agent）

✅ 内容工程优先
✅ 结构化优先

---

## ⚠️ 潜在问题与优化方向

### 🔴 关键问题点

#### 1. LLM拆解的一致性问题
- 同类剧情单元可能被拆解成完全不同的结构
- 不同时间调用LLM，结果差异巨大
- 缺乏拆解标准和评估机制

#### 2. 检索精度问题
- 多索引（冲突+情绪+人物+功能）如何组合？
- 混合检索的权重策略未定义
- 向量检索 + 元数据过滤的融合方案缺失

#### 3. 人物一致性过于理想化
- 情绪衰减机制未设计
- 目标驱动的剧情生成逻辑缺失
- 多人物交互时的冲突协调未考虑

#### 4. 数据质量瓶颈
- 小说是线性叙事，拆解为剧情单元会丢失时序关系
- 上下文依赖（铺垫、伏笔）可能被割裂
- 情绪曲线是动态的，静态存储不够

---

### 🟡 优化建议

#### 1. 结构化拆解标准化
- 引入剧情单元分类体系（如《救猫咪》15个节拍）
- LLM拆解时输出标签+置信度
- 人工审核+半自动修正机制

#### 2. 增加时序索引
- 前置依赖（这场戏之前发生了什么）
- 后置影响（这场戏导致了什么）
- 时间线位置（第X章第Y节）

#### 3. RAG检索策略优化
- 多阶段检索：先粗筛（冲突类型），再细筛（情绪+人物），最后向量精排
- 重排序模型：用Cross-Encoder提升相关性
- 负采样：明确"不要检索什么"（如风格不匹配的剧情）

#### 4. 人物系统分层设计
```
静态层：核心性格、背景设定
动态层：当前情绪、关系状态
目标层：短期目标、长期动机
约束层：底线、禁忌行为
```

#### 5. MVP快速验证
- 不需要全流程，先验证单环节
- 只做"冲突检索+单场戏生成"，看看效果如何

---

### 🔥 核心难点

#### 1. 剧情连贯性（最难）
RAG擅长检索相似片段，但：
- 如何保证检索的多个剧情单元能逻辑自洽？
- 节奏如何控制？不能全是高潮，也不能全是平淡
- 长线伏笔如何埋设和回收？

#### 2. 评估标准缺失
- 什么算"好"的剧本？
- 如何量化"冲突强度"、"情绪张力"？
- 缺乏自动化评估机制，只能靠人工审阅

#### 3. LLM生成的不稳定性
- 同样的Prompt，每次生成质量差异大
- 温度参数如何平衡"创意"和"一致性"？
- 生成质量如何稳定控制？

#### 4. 冷启动和数据标注成本
- 需要大量小说作为训练数据
- LLM拆解结果需要人工校对（很耗时）
- 如何用最少标注达到最大效果？

#### 5. 商业落地的实用性
- 生成速度：单场戏生成需要多久？
- 成本：Token消耗是否可接受？
- 与人类编剧协作的边界在哪里？

---

### 📊 建议优先级调整

原方案：
1. 剧情结构化
2. RAG检索
3. 人物系统
4. 长线规划
5. Prompt工程化

建议调整：
1. 标准化拆解体系（先定义schema）
2. 单场戏生成验证（小闭环验证）
3. 检索+生成Pipeline（打通流程）
4. 人物一致性约束（核心功能）
5. 长线剧情规划（高级功能）

---

### 🚦 效果不佳时的决策标准

#### 何时果断放弃
- 核心假设被证伪（RAG对生成无帮助）
- 技术瓶颈无法突破（拆解一致性、生成稳定性）
- 商业价值不成立（成本、速度、质量不达标）
- 用户/市场反馈差（编剧不愿用、生成无灵魂）

#### 何时继续优化
- 有局部价值（某个环节有效）
- 方向正确但执行有问题
- 找到了具体瓶颈和优化路径
- 竞品验证了可行性

#### 快速测试决策流程

第1周：MVP快速验证
- 只做1个冲突类型（如"背叛"）
- 拆解5-10个样本剧情
- 生成10-20场戏
- 人工评估质量

第2-3周（如果继续）：深度测试
- 扩展到3-5个冲突类型
- 优化检索策略
- 加入人物约束
- 小规模A/B测试

第4周（如果继续）：商业验证
- 计算实际成本（Token + 时间）
- 对比人工编剧成本
- 评估规模化可行性

**任何阶段不达标，立即止损**

---

## 🎯 核心结论

👉 成败不在模型强弱
👉 在于剧情抽象与结构设计能力

真正壁垒：

- 剧情模式知识库
- 冲突与节奏工程化
- 人物一致性系统

---

如果未来扩展：

- 自动评分模型
- 剧情节奏优化
- 数据规模扩大

再逐步升级架构即可。

